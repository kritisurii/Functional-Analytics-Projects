{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6731893",
   "metadata": {},
   "source": [
    "# Poem Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "58002c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, PoemTokenizer\n",
    "english_stop_words = stopwords.words('english')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# machine learning\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, GlobalMaxPooling1D, SpatialDropout1D\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "65bfb870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the file\n",
    "df = pd.read_csv(\"C:/Users/chira/OneDrive - fsm.ac.in/Desktop/Poem dataset.csv\",sep=\",\", encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c964d75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 749 entries, 0 to 748\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  749 non-null    int64 \n",
      " 1   Context     749 non-null    object\n",
      " 2   Review      749 non-null    int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 17.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# information of the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6a892023",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Context</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>with pale blue berries. in these peaceful shad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it flows so long as falls the rain,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>and that is why, the lonesome day,</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>when i peruse the conquered fame of heroes, an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>of inward strife for truth and liberty.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            Context  Review\n",
       "0           0  with pale blue berries. in these peaceful shad...       1\n",
       "1           1                it flows so long as falls the rain,       0\n",
       "2           2                 and that is why, the lonesome day,      -1\n",
       "3           3  when i peruse the conquered fame of heroes, an...       2\n",
       "4           4            of inward strife for truth and liberty.       2"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "36d1eb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  0, -1,  2], dtype=int64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Review.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e0319855",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=df.Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "872f85a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 0, 0: 2, 1: 1, 2: 3}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here -1 is negative, 2 is no impact, 1 is positive and 3 is mixed\n",
    "\n",
    "{-1: 0, 0: 2, 1: 1, 2: 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f81be30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df['Review'].replace(['2'], '3')\n",
    "df['Review'] = df['Review'].replace(['0'], '2')\n",
    "df['Review'] = df['Review'].replace(['-1'], '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a0ef6d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2     -1\n",
       "3      2\n",
       "4      2\n",
       "      ..\n",
       "744    0\n",
       "745    1\n",
       "746   -1\n",
       "747    0\n",
       "748   -1\n",
       "Name: Review, Length: 749, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "3e4b925e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "Context       0\n",
       "Review        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking null values in dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3558dfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(599,)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data\n",
    "X_train, X_valid = train_test_split(df['Context'],\n",
    "                                  random_state=123,\n",
    "                                  train_size=0.80    # 99% vs 1%\n",
    "                                 )\n",
    "\n",
    "print(X_train.shape)     # (1467709, 12)\n",
    "print(X_valid.shape)     # (14826, 12) 1% of above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "5034d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_WITH_SPACE = re.compile(\"(@)\")\n",
    "SPACE = \" \"\n",
    "# preprocess on the poem and removing @ \n",
    "def preprocess_reviews(reviews):  \n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line.lower()) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "# preprocess training data based of poem\n",
    "reviews_train_clean = preprocess_reviews(df.Context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f225e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all stop words and doing further p;reprocessing on the poem data\n",
    "def remove_stop_words(corpus):\n",
    "    removed_stop_words = []\n",
    "    for review in corpus:\n",
    "        removed_stop_words.append(\n",
    "            ' '.join([word for word in review.split()  if word not in english_stop_words]))\n",
    "    return removed_stop_words\n",
    "\n",
    "# removing stop words from training data\n",
    "no_stop_words_train = remove_stop_words(reviews_train_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ce04b9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# created a function for stemming words\n",
    "def get_stemmed_text(corpus):\n",
    "    stemmer = PorterStemmer()\n",
    "    return [' '.join([stemmer.stem(word) for word in review.split()]) for review in corpus]\n",
    "\n",
    "# stemming text on train data\n",
    "stemmed_reviews_train = get_stemmed_text(no_stop_words_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "088c758b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Tokenizer method to filter out special character and initializing its method\n",
    "tokenizer = Tokenizer(\n",
    "    num_words = 8000,\n",
    "    filters = '\"#$%&()*+-/:;<=>@[\\]^_`{|}~'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2f942447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Tokenizer method converting training poem data to 3000 features\n",
    "tokenizer.fit_on_texts(stemmed_reviews_train)\n",
    "X_train = tokenizer.texts_to_sequences(stemmed_reviews_train)\n",
    "X_train = pad_sequences(X_train, maxlen = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "636b5e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (749, 3000)\n",
      "Training labels: (749,)\n"
     ]
    }
   ],
   "source": [
    "#checking shape\n",
    "print(\"Training features:\",X_train.shape)\n",
    "print(\"Training labels:\", target_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5321eea9",
   "metadata": {},
   "source": [
    "# Preprocessing and cleaning data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "00aea43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data feature\n",
    "poem_train = df[\"Context\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "27747d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Tokenizer method to filter out special character and initializing its method\n",
    "tokenizer = Tokenizer(\n",
    "    num_words = 8000,\n",
    "    filters = '\"#$%&()*+-/:;<=>@[\\]^_`{|}~'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b6f94dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Tokenizer method converting training peom data to 3000 features\n",
    "tokenizer.fit_on_texts(poem_train)\n",
    "x_train = tokenizer.texts_to_sequences(poem_train)\n",
    "x_train = pad_sequences(x_train, maxlen = 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "798f5503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 128)               384128    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_352 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_353 (Dropout)       (None, 512)               0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_354 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,003,060\n",
      "Trainable params: 1,003,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating a sequential model with dense layers, dropouts and all activation function as relu to remove \n",
    "#negative value and last activation function as softamx for getting final value and initialized weights in first two layer\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim = x_train.shape[1], activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "# summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4e3f0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the custom DL based model with loss calculated on the basis of categorical_crossentropy, with adam optimizer and used accuracy as metrics\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9aca5e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: (749, 3000)\n",
      "Training labels: (749, 3)\n"
     ]
    }
   ],
   "source": [
    "# shape\n",
    "print(\"Training features:\",x_train.shape)\n",
    "print(\"Training labels:\", y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "43d0b9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\chira\\anaconda3\\lib\\site-packages (4.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: requests in c:\\users\\chira\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\chira\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from transformers) (0.11.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\chira\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chira\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bc5bb059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing hugging face transformer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e6543708",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df[\"Context\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "925d9d5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at siebert/sentiment-roberta-large-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#importing \"siebert/sentiment-roberta-large-english\" from hugging face\n",
    "classifier1 = pipeline(\"sentiment-analysis\",\n",
    "                         model=\"siebert/sentiment-roberta-large-english\"\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "6a3636e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting poem  from the dataset\n",
    "df1=df['Context'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0c185aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to t5-small and revision d769bba (https://huggingface.co/t5-small).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-small.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "C:\\Users\\chira\\anaconda3\\lib\\site-packages\\transformers\\models\\t5\\tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-small automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "36c4751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 100, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n",
      "Your max_length is set to 100, but you input_length is only 12. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=6)\n",
      "Your max_length is set to 100, but you input_length is only 15. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n",
      "Your max_length is set to 100, but you input_length is only 35. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n",
      "Your max_length is set to 100, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'pale blue berries in these peaceful shades-- with pale blueberries . in these hues-- the berries are ripe and berry-like .'},\n",
       " {'summary_text': 'it flows so long as falls the rain . it flows . so long . as falls . the rain, the rain and the sand .'},\n",
       " {'summary_text': \"the lonesome day, a day of london's worst ever, is a year of mourning . it's the first time we've had a great day .\"},\n",
       " {'summary_text': 'when i peruse the conquered fame of heroes and the victories of mighty generals, i do not envy the generals .'},\n",
       " {'summary_text': 'of inward strife for truth and liberty . of truth and freedom . if you are a savior, please contact us on 0800 555 111 .'}]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#summary  from hugging face\n",
    "summarizer(df1[:5].values.tolist(),max_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b2642f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Text Generation from hugging face\n",
    "generator = pipeline('text-generation', model = 'gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a01533c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'generated_text': 'with pale blue berries. in these peaceful shades--as in the woods. There are two types of berries on each side of the stem--the white \"brysey\" and the red \"bryseye.\" The white \"bryseye\" is almost a black-and-white kind of berries. The red \"bryseye\" is the most unusual kind in the picture. To be perfectly clear of color all berries are blue.\\n\\n\\nThe white \"brysey'},\n",
       "  {'generated_text': 'with pale blue berries. in these peaceful shades--these are the first fruits of our love to flowers, the first time we really began to love these flowers.\\n\\n\\nHAPPENING TO A GOOD LOSS OF TIME\\n\\nIt is the good lost sleep which brings a new good.\\n\\n\\nHUMAN WASHING IN COLD\\n\\nThe night before breakfast, your skin and clothes dry to the skin. This will bring a new feeling. And the new feeling will come from'},\n",
       "  {'generated_text': 'with pale blue berries. in these peaceful shades--the first hint of light, which had faded by night; a blueish grayness. Then the last of the green, the most pure, and with all the rest at once dull blackness in it of every sort and nature.\\n\\nThis, and this was the second part of this story, so that I never have to do them again, I thought to myself, when I first saw it, I was on my way to an old'}],\n",
       " [{'generated_text': 'it flows so long as falls the rain, and the rains do not fall until the second, the last, the most lasting of periods. Then the great rains and great rains will give great, or at least great amount of rain. Because the rain will not change the year, the last, the most lasting, a period will not be so long. But when the man who did the rain, will not be brought back, and the last man with no money, will be brought back with money'},\n",
       "  {'generated_text': 'it flows so long as falls the rain, and it must drop quickly, making it impossible then not to have it. Now I have a little trouble with that part of the weather that falls over the surface, which is the westerly side; and I believe I shall have it in an hour or two; so to carry off the westerly end of the wind I carry it in the westerly direction.\\n\\nIt will be seen that you must make use of two kinds of'},\n",
       "  {'generated_text': \"it flows so long as falls the rain, if it falls so much, it flows so long that it has a very bad effect on the ground. You lose the rain if you're going to fall by it, and then it loses its effect. There are other things, like those that are in the river, the roots of the wood, the rocks, that are not in the roots of the tree, just don't flow as easily as those water-related things. So at any rate in\"}],\n",
       " [{'generated_text': \"and that is why, the lonesome day, I have seen and experienced this great pleasure. If anyone, anywhere, asks me where I could put the original video, I am so glad to take it, because it's so much more powerful. I still have to take my children to school. No school has had a more rewarding time than at your school. I am happy to spend it all in one afternoon when I have my children at home with me. With Mom and dad. So\"},\n",
       "  {'generated_text': 'and that is why, the lonesome day, they came after to make peace.\"\\n\\n\"We are the last ones after them; there is no other place here.\"\\n\\nNawar said: \"These, then, were among them who sent us to make up such things. Some of them had gone from their homes, and we used to run outside.\\n\\nWhen I saw them on the way, I came to see the lonesome-day that a great king'},\n",
       "  {'generated_text': 'and that is why, the lonesome day, at night, we hear stories of a man to leave his country a place which is in darkness. This is strange for one thing: we are afraid of these men. And it is even more strange when we read about an old man who has vanished, leaving behind him a man who was the head of his village, as well as a man who was a brother. Is it too much to say that the world does not see these strange occurrences'}],\n",
       " [{'generated_text': 'when i peruse the conquered fame of heroes, and the victories of mighty generals, i do not envy the generals, but the people; for they alone know the greatness of princes and armies; and if they could do not, they would neither come nor go, as they, when they were kings, did; but when kings come to power, the people of their subjects do much. 2 And when we ask whether men are in need of our power, we answer that because we know so much'},\n",
       "  {'generated_text': \"when i peruse the conquered fame of heroes, and the victories of mighty generals, i do not envy the generals, and despise the generals' superiority, but have no hatred for their greatness; for, if we desire, we ought to do what is in common with people themselves, according to their own opinions, and in accordance with what their own mind will do, i.e., to support those who have supported them, when the latter's own opinion is ill suited to the case. If\"},\n",
       "  {'generated_text': \"when i peruse the conquered fame of heroes, and the victories of mighty generals, i do not envy the generals, nor my friend a fellow man. Every one that will bear an eye against an enemy's chief, and shall not yield the same to his adversaries, that in the end he should be the father of his own nation, I will keep, and will fight, for the safety of my country and the happiness of the world. I shall have a sword to my own arm, and\"}],\n",
       " [{'generated_text': 'of inward strife for truth and liberty.\\n\\nThe Lord Jesus Christ has said:\\n\\n\"For what God has given you, I did not give you, and I will not continue to give you. My servant James has said:\\n\\n\"Therefore seek forgiveness also; and if possible, if possible, keep your faith. My servant John the Baptist, in his epistles:\\n\\n\"\\'You may forgive one another. \\'Be merciful to a little. For there is a certain'},\n",
       "  {'generated_text': 'of inward strife for truth and liberty. It is to be expected not merely in the government of this country but in this nation that we do not regard politics as a mere political matter, nor are we willing to acknowledge the existence of it. But what is politics and what are we willing to admit? To all men; to every man. A state for you and me and to all those who live there- selves- they have long been known, and to have long been regarded as a social entity'},\n",
       "  {'generated_text': 'of inward strife for truth and liberty. I was led by a youth, a man of faith, a man of wisdom, a man who was an emissary to the God to help his people.\"\\n\\nA little while later, when he was fifty, on his twenty-first anniversary, in April, he was ordained the bishop of St. Peters, Pennsylvania.\\n\\nIn St. Peters, Pennsylvania is the town called St. Johns. The place is a church with a cemetery,'}]]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text generating for first 5 poem extracts\n",
    "generator(df1[:5].values.tolist(), max_length = 100, num_return_sequences=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e3925f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "577ac2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\chira\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing vader library\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "887e1a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Context</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>with pale blue berries. in these peaceful shad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it flows so long as falls the rain,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>and that is why, the lonesome day,</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>when i peruse the conquered fame of heroes, an...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>of inward strife for truth and liberty.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>887</td>\n",
       "      <td>to his ears there came a murmur of far seas be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>888</td>\n",
       "      <td>the one good man in the world who knows me, --</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>889</td>\n",
       "      <td>faint voices lifted shrill with pain</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>890</td>\n",
       "      <td>an', fust you knowed on, back come charles the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>891</td>\n",
       "      <td>in the wild glens rough shepherds will deplore</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>749 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                            Context  Review\n",
       "0             0  with pale blue berries. in these peaceful shad...       1\n",
       "1             1                it flows so long as falls the rain,       0\n",
       "2             2                 and that is why, the lonesome day,      -1\n",
       "3             3  when i peruse the conquered fame of heroes, an...       2\n",
       "4             4            of inward strife for truth and liberty.       2\n",
       "..          ...                                                ...     ...\n",
       "744         887  to his ears there came a murmur of far seas be...       0\n",
       "745         888     the one good man in the world who knows me, --       1\n",
       "746         889               faint voices lifted shrill with pain      -1\n",
       "747         890  an', fust you knowed on, back come charles the...       0\n",
       "748         891     in the wild glens rough shepherds will deplore      -1\n",
       "\n",
       "[749 rows x 3 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a980c6aa",
   "metadata": {},
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6feebe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#measuring polarity and sentiment analysis\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "df['compound'] = [analyzer.polarity_scores(x)['compound'] for x in df['Context']]\n",
    "df['neg'] = [analyzer.polarity_scores(x)['neg'] for x in df['Context']]\n",
    "df['neu'] = [analyzer.polarity_scores(x)['neu'] for x in df['Context']]\n",
    "df['pos'] = [analyzer.polarity_scores(x)['pos'] for x in df['Context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6145536c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Context</th>\n",
       "      <th>Review</th>\n",
       "      <th>compound</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>with pale blue berries. in these peaceful shad...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it flows so long as falls the rain,</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>and that is why, the lonesome day,</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.3612</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>when i peruse the conquered fame of heroes, an...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7914</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>of inward strife for truth and liberty.</td>\n",
       "      <td>2</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>887</td>\n",
       "      <td>to his ears there came a murmur of far seas be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>888</td>\n",
       "      <td>the one good man in the world who knows me, --</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4404</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>889</td>\n",
       "      <td>faint voices lifted shrill with pain</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>890</td>\n",
       "      <td>an', fust you knowed on, back come charles the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>891</td>\n",
       "      <td>in the wild glens rough shepherds will deplore</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>749 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                            Context  Review  \\\n",
       "0             0  with pale blue berries. in these peaceful shad...       1   \n",
       "1             1                it flows so long as falls the rain,       0   \n",
       "2             2                 and that is why, the lonesome day,      -1   \n",
       "3             3  when i peruse the conquered fame of heroes, an...       2   \n",
       "4             4            of inward strife for truth and liberty.       2   \n",
       "..          ...                                                ...     ...   \n",
       "744         887  to his ears there came a murmur of far seas be...       0   \n",
       "745         888     the one good man in the world who knows me, --       1   \n",
       "746         889               faint voices lifted shrill with pain      -1   \n",
       "747         890  an', fust you knowed on, back come charles the...       0   \n",
       "748         891     in the wild glens rough shepherds will deplore      -1   \n",
       "\n",
       "     compound    neg    neu    pos  \n",
       "0      0.4939  0.000  0.686  0.314  \n",
       "1      0.0000  0.000  1.000  0.000  \n",
       "2     -0.3612  0.294  0.706  0.000  \n",
       "3      0.7914  0.000  0.652  0.348  \n",
       "4      0.6908  0.000  0.467  0.533  \n",
       "..        ...    ...    ...    ...  \n",
       "744    0.0000  0.000  1.000  0.000  \n",
       "745    0.4404  0.000  0.775  0.225  \n",
       "746   -0.5106  0.398  0.602  0.000  \n",
       "747    0.0000  0.000  1.000  0.000  \n",
       "748    0.0000  0.000  1.000  0.000  \n",
       "\n",
       "[749 rows x 7 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776baac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
